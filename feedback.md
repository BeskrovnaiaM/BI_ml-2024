Отдельный респект за `requirements.txt`! На будущее, указывай туда еще и версии - потому что при если у тебя есть что-то, что в новой версии переделали, то код все равно может упасть.

# 1. EDA
## 1.1
Для лучшей визуализации может быть удобнее отключать отображение осей на картинках, как вариант:
```{python}
axs[row, col].imshow(image)
axs[row, col].set_title(f'Class: {int(class_label)}')
axs[row, col].axis("off")
```

## 1.2
Супер! Вопросов нет

## 1.3
Вопросов нет, сплит реализован корректно, то, что используешь глобальный сид - тоже респект.


## 1.4 KNN
Отлично, что реализовала кастинг в инты, вообще все, что можно, нужно переводить в численные типы, потому что нейронки и машинное обучение только с ними и работают :)


Круто реализован подход без циклов! 

Предсказания для классов реализованы правильно. Но можно сделать это в векторном виде сразу для всего `X`. Как? Подсказка - заменить операциями из нампая цикл в `predict_labels_binary`. Сниму четверть балла за неэффективную реализацию для бинарной классификации. В таком коле легко запутаться и допустить ошибку.

В коде `predict` ошибка для `n_loops=1` - у тебя функция названа `compute_distances_one_loop`, а вызывается `compute_distances_one_loop[s]` выглядит, как ты скопировала имя функции и поменяла two на one и не протестировала. Снимаю четверть балла, в будущем используй редактор кода, с которым легче такое отлавливать.

Метрики для бинарной классификации реализованы в целом правильно, но не учитывают, что при подсчете дроби знаменатель может быть нулевой, поэтому тут сниму четверть балла - код не до конца избавлен от падений. Но в таком виде их лучше не возвращать, без пояснения - мне пришлось залезть в код, так как я проверяющий, но ноутбук с таким выводом ничего не скажет про метрики, так как непонятно, какая что показывает - `(0.9714285714285714, 1.0, 0.9855072463768115, 0.9841269841269841)`, и то же самое с метриками из sklearn - просто назвать одной буквой переменую недостаточно. Всегда поясняй название числа, которое выводишь - вынужден снять за это четверть балла.


В функции `find_best_k` излишнее усложнение - ты уже передаешь метрику как функцию и не нужно проверять ее на равность какому-то критерию - так ты сужаешь логику, которая по-хорошему обобщалась бы на любое количество метрик. А тут ты ограничиваешься только четырьмя метриками, проверяя их. Из-за этого если на вход придет нечто другое - например `mse`, то все равно посчитается точность. Поэтому это не совсем корректная реализация, плюс внутри у тебя `metric` никак не используется, а все еще функция опирается на глобальный объект `binary_classification_metrics`, что некорректно. Снимаю полбалла (по четвертинке за каждый из недочетов)

У тебя отсутствует анализ наиболее подходящего `k` - снимаю балл.

## 1.5 Multiclass KNN

Опять же, печатай всегда, что за число ты выводишь! 

`find_best_k_multiclass` реализована неправильно - у тебя в сигнатуре функции есть параметр `metric`, ты его не используешь и проверяешь только точность, но точность не самый объективный показатель, Поэтому в дальнейшем у тебя может не получиться провезти полноценный анализ и сделать из него правильный выводы. Снимаю балл за это и за отсутствие анализа наиболее удачного `k`.

При эффективной реализации твой комп вполне может справиться с таким небольшим датасетом, это не оправдание, к сожалению. Тем более, на работе такое точно не прокатит - снимаю полбалла - неэффективная реализация + из-за этого повлекшиеся потенциальные неправильные метрики. В любом случае, ты могла хотя бы оценить получанные значения, нарисовав усредненные траектории по нескольким запускам, а не просто рандомный выбор 500 значений.


# 2 EDA

## 2.1

Нет EDA, и ты не пояснила, что ты делаешь с данными - всегда нужно это репортить, особенно в дальнейшей работе! За первый и второй пункт снимаю 1 балл в совокупности. Пайплайн у тебя тоже не реализован. В него можно было бы воткнуть к примеру трансформацию категориальных признаков - у тебя есть признак пола, который хорошо бы представить в виде колонки со значением 0 и 1.

## 2.2-2.4

Метрики реалищованы правильно! Забыла опять пояснение к принту! 


Опять же, функция `find_best_k_R` реализована недостаточно корректно - она поддерживает только три метрики, и это неправильно. Это легко можно исправить, если ты просто напишешь:

```{python}

train_metric_k = metric(y_pred_train, y_train)
test_metric_k = metric(y_pred_test, y_test)
train_metrics.append(train_metric_k)
test_metrics.append(test_metric_k)

```
И Все!) Это и читаемо, и поддерживаемо! Пожалуйста запомни и в следующий раз не сравнивай функции на равенство, иногда они тоже могут не сработать, если ты функцию во что-нибудь обернёшь (например в декоратор)

Поэтому за реализацию этой функции я снимаю балл, как и в предыдущем случае. И за отсутствие интерпретации графика - снимаю четверть балла.


# 3 Social

+ rep  и доп баллы за фоточку!


Итог:
- 1.1 - 0.5/0.5
- 1.2 - 1/1
- 1.3 - 0.5/0.5
- 1.4 - 3.5/6 (снял за неинформативные принты метрик, ошибку в `predict` в имени функции, неэффективную реализацию предсказания для бинарной классификации, некорректную реализацию `find_best_k`, отсутствие анализа графиков)
- 1.5 - 0.5/2 (некорректная реализация `find_best_k_multiclass` + неэффективность реализации предсказания для многих классов, из-за чего необоснованное урезание выборки)
- 2.1 - 1/2 нет EDA и пояснений к трансформациям, пайплайн не реализовала `:(`
- 2.2 - 1/1
- 2.3 - 3/3
- 2.4 - 1.25/2 (некорректная реализация `find_best_k_R` + отсутствие анализа графиков)
- 3 - 0.5


ШТРАФЫ: У тебя их нет) Отдельное спасибо тебе за `requirements.txt`, это очень хорошо, что ты его вставила, впредь пожалуйста делай это с версиями. Поэтому я за негро тебе тоже хочу добавить 0.25 балла!

TOTAL: 12.25 + 0.5 + 0.25 = 13